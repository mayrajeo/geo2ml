{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d009d3-7c02-4266-868e-34f75bf55f42",
   "metadata": {},
   "source": [
    "# Dataset creation\n",
    "\n",
    "> CLI commands for creating different types of datasets from remote sensing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbad97-3c72-47b8-b2d2-4554d503f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scripts.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c33f0-6a14-46f2-a0cd-d39873cc3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb71d5-b5f6-49b3-84cf-8c596a9d8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from fastcore.script import *\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from geo2ml.data.tabular import *\n",
    "from geo2ml.data.tiling import Tiler\n",
    "from geo2ml.data.cv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97d7de8-a21a-487d-9ec5-a378345954f7",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447739ee-a8c5-4025-92a5-3714f5c2c3e2",
   "metadata": {},
   "source": [
    "`geo2ml` provides the following commands for creating datasets from geospatial raster and vector data.\n",
    "\n",
    "* `geo2ml_sample_points`\n",
    "* `geo2ml_sample_polygons`\n",
    "* `geo2ml_create_raster_dataset`\n",
    "* `geo2ml_create_yolo_dataset`\n",
    "* `geo2ml_create_coco_dataset`\n",
    "\n",
    "These commands can be either used from CLI using `geo2ml_` -prefixed commands, or used in python scripts or notebooks like \n",
    "\n",
    "```python\n",
    "from geo2ml.scripts.data import sample_points\n",
    "\n",
    "sampling_locations = Path(<path_to_locations>)\n",
    "input_raster = Path(<path_to_raster>)\n",
    "target_column = 'column'\n",
    "outpath = Path(<path_to_save_files>)\n",
    "\n",
    "sample_points(sampling_locations, input_raster, target_column, outpath)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ccf13-9cc8-4a99-8e94-012a0e531295",
   "metadata": {},
   "source": [
    "## Tabular datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9ca96-41f5-4b93-88f8-1ae3ccc8e1a7",
   "metadata": {},
   "source": [
    "Both of these commands create a dataset by sampling point or polygon values provided in `sampling_locations` from `input_raster` and save the resulting table as a csv and geojson or shapfile to `outpath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7da447-20d0-4711-a8bc-e8c1348a5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@call_parse\n",
    "def sample_points(sampling_locations:Path, # Path to the geojson/shapefile containing the sampling locations as points\n",
    "                  input_raster:Path, # Path to the raster used for sampling\n",
    "                  target_column:str, # Column of `sampling_locations` used as the target\n",
    "                  outpath:Path, # Path to save the output files. Is created if doesn't exist\n",
    "                  gpkg_layer:str=None, # If `sampling_locations` is .gpkg, specify the layer used. Ignored otherwise.\n",
    "                  save_as_shp:bool=False, # Save results as shapefiles? If False, saves as geojson\n",
    "                  rename_target:str=None, # If provided, target column is renamed to this\n",
    "                  band_names:Path=None, # Path to a file providing bands to use as rows\n",
    "                  dropna_value:int=None, # Drop all rows with all values equal to this value\n",
    "                  out_prefix:str=\"\"): # Prefix for outputs\n",
    "    \"Sample pixel values from `input_raster` using `sampling_locations`\" \n",
    "\n",
    "    if band_names:\n",
    "        with open(band_names) as f: \n",
    "            bandnames = [l.strip() for l in f.readlines()]\n",
    "    \n",
    "    gdf = sample_raster_with_points(sampling_locations, input_raster, target_column, band_names=band_names)\n",
    "\n",
    "    df = gdf.drop(columns=['geometry'])\n",
    "\n",
    "    if dropna_value:\n",
    "        df = df.loc[~(df[bands] == dropna_value).all(axis=1)]\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    shp_stem = sampling_locations.stem\n",
    "    raster_stem = input_raster.stem\n",
    "\n",
    "    outpath.mkdir(parents=True, exist_ok=True)\n",
    "    out_stem = Path(f'{raster_stem}__{shp_stem}__{target_column}')\n",
    "\n",
    "    if out_prefix != \"\":\n",
    "        out_stem = Path(f'{out_prefix}__{out_stem}')\n",
    "\n",
    "    suffix = '.shp' if save_as_shp else '.geojson'\n",
    "\n",
    "    gdf.to_file(outpath/out_stem.with_suffix(suffix))\n",
    "    df.to_csv(outpath/out_stem.with_suffix('.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce64191-ea3c-4fb3-9bc0-87808a88a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@call_parse\n",
    "def sample_polygons(sampling_locations:Path, # Path to the geojson/shapefile containing the sampling locations as polygons\n",
    "                    input_raster:Path, # Path to the raster used for sampling\n",
    "                    target_column:str, # Column of `sampling_locations` used for sampling\n",
    "                    outpath:Path, # Path to save the output files. Is created if doesn't exist\n",
    "                    min:bool, # Compute minimum\n",
    "                    max:bool, # Compute maximum\n",
    "                    mean:bool, # Compute mean\n",
    "                    count:bool, # Compute count\n",
    "                    sum:bool, # Compute sum\n",
    "                    std:bool, # Compute standard deviation\n",
    "                    median:bool, # Compute median\n",
    "                    categorical:bool=False, # Are bands categorical data?\n",
    "                    gpkg_layer:str=None, # If `sampling_locations` is .gpkg, specify the layer used. Ignored otherwise.\n",
    "                    save_as_shp:bool=False, # Save results as shapefiles? If False, saves as geojson\n",
    "                    rename_target:str=None, # If provided, target column is renamed to this\n",
    "                    band_names:Path=None, # Path to a file providing bands to use as rows\n",
    "                    dropna_value:int=None, # Drop all rows with all values equal to this value\n",
    "                    out_prefix:str=\"\"): # Prefix for outputs\n",
    "    \"Sample pixel values from `input_raster` using `sampling_locations`. \" \n",
    "\n",
    "    stats = []\n",
    "    if min: stats.append('min')\n",
    "    if max: stats.append('max')\n",
    "    if mean: stats.append('mean')\n",
    "    if count: stats.append('count')\n",
    "    if sum: stats.append('sum')\n",
    "    if std: stats.append('std')\n",
    "    if median: stats.append('median')\n",
    "\n",
    "    if band_names:\n",
    "        with open(band_names) as f: \n",
    "            bandnames = [l.strip() for l in f.readlines()]\n",
    "    \n",
    "    gdf = sample_raster_with_polygons(sampling_locations, input_raster, target_column, band_names=band_names,\n",
    "                                      stats=stats, categorical=categorical)\n",
    "\n",
    "    df = gdf.drop(columns=['geometry'])\n",
    "\n",
    "    if dropna_value:\n",
    "        df = df.loc[~(df[bands] == dropna_value).all(axis=1)]\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    shp_stem = sampling_locations.stem\n",
    "    raster_stem = input_raster.stem\n",
    "\n",
    "    outpath.mkdir(parents=True, exist_ok=True)\n",
    "    out_stem = Path(f'{raster_stem}__{shp_stem}__{target_column}')\n",
    "\n",
    "    if out_prefix != \"\":\n",
    "        out_stem = Path(f'{out_prefix}__{out_stem}')\n",
    "\n",
    "    suffix = '.shp' if save_as_shp else '.geojson'\n",
    "\n",
    "    gdf.to_file(outpath/out_stem.with_suffix(suffix))\n",
    "    df.to_csv(outpath/out_stem.with_suffix('.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2edab60-d02a-4c8d-81cb-b57f94f58139",
   "metadata": {},
   "source": [
    "## Computer vision dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c4a8b-5c12-4c53-b3f9-32b50648b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@call_parse\n",
    "def create_raster_dataset(\n",
    "    raster_path:Path, # Path to a raster that is the base for the dataset\n",
    "    mask_path:Path, # Path to corresponding mask raster or polygon layer. Must have the same extent and resolution as the raster in `raster_path`\n",
    "    outpath:Path, # Where to save the results\n",
    "    save_grid:bool=False, # Whether to save the tiling grid\n",
    "    target_column:str=None, # If mask_path contains vector data, identifier of the column containing the class information\n",
    "    gpkg_layer:str=None, # If `polygon_path` is a geopackage, specify the layer used. Ignored otherwise.\n",
    "    gridsize_x:int=256, # Size of tiles in x-axis in pixels\n",
    "    gridsize_y:int=256, # Size of tiles in y-axis in pixels\n",
    "    overlap_x:int=0, # Overlap of tiles in x-axis in pixels\n",
    "    overlap_y:int=0, # Overlap of tiles in y-axis in pixels\n",
    "):\n",
    "    \"Create a semantic segmentation dataset from a `raster_path` and corresponding mask `mask_path`. Raster image patches are saved to `outpath/raster_tiles` and mask patches to `outpath/mask_tiles`\"\n",
    "    tiler = Tiler(outpath, gridsize_x=gridsize_x, gridsize_y=gridsize_y, overlap=(overlap_x, overlap_y))\n",
    "    tiler.tile_raster(raster_path)\n",
    "    \n",
    "    polygon_extensions = ['.shp', '.geojson', '.gpkg']\n",
    "    raster_extensions = ['.tif']\n",
    "\n",
    "    if mask_path.suffix in raster_extensions:\n",
    "        tiler.raster_path = outpath/'mask_images'\n",
    "        tiler.tile_raster(mask_path)\n",
    "    elif mask_path.suffix in polygon_extensions:\n",
    "        if not target_column:\n",
    "            raise Exception(\n",
    "                \"If mask_path contains polygon data, target_column must be provided\"\n",
    "            )\n",
    "        tiler.tile_and_rasterize_vector(raster_path, mask_path, column=target_column, gpkg_layer=gpkg_layer)\n",
    "        os.rename(tiler.rasterized_vector_path, outpath/'mask_images')\n",
    "    if save_grid: tiler.grid.to_file(outpath/'grid.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5094c-ad46-45cc-b7fd-ce8746689aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@call_parse\n",
    "def create_coco_dataset(\n",
    "    raster_path:Path, # Path to a raster that is the base for the dataset\n",
    "    polygon_path:Path, # Path to annotated polygons\n",
    "    target_column:str, # Which column contains class information\n",
    "    outpath:Path, # Where to save the resulting files\n",
    "    dataset_name:str, # Name of the dataset\n",
    "    gpkg_layer:str=None, # If `polygon_path` is a geopackage, specify the layer used. Ignored otherwise.\n",
    "    min_area_pct:float=0.0, # How small polygons keep after tiling?\n",
    "    save_grid:bool=False, # Should tiling grid be saved\n",
    "    gridsize_x:int=320, # Size of tiles in x-axis in pixels\n",
    "    gridsize_y:int=320, # Size of tiles in y-axis in pixels\n",
    "    overlap_x:int=0, # Overlap of tiles in x-axis in pixels\n",
    "    overlap_y:int=0, # Overlap of tiles in y-axis in pixels\n",
    "    ann_format:str='box', # Annotation format, either box, polygon or rotated box\n",
    "    min_bbox_area:int=0 # Minimum bounding gox area in pixels. Smaller objects than this are discarded\n",
    "):\n",
    "    \"Create a COCO-format dataset from `raster` and `polygon` shapefile\"\n",
    "    tiler = Tiler(outpath, gridsize_x=gridsize_x, gridsize_y=gridsize_y, overlap=(overlap_x, overlap_y))\n",
    "    tiler.tile_raster(raster_path)\n",
    "    tiler.tile_vector(polygon_path)\n",
    "\n",
    "    cats = gpd.read_file(polygon_path)[target_column].unique()\n",
    "\n",
    "    coco_cats = [{'supercategory':'object', 'id':i+1, 'name':c} for i, c in enumerate(cats)]\n",
    "    coco_info = {'description': dataset_name,\n",
    "                 'version': 0.1,\n",
    "                 'year': datetime.date.today().year,\n",
    "                 'contributor': \"Your name\",\n",
    "                 'date_created': datetime.date.today().strftime(\"%Y/%m/%d\")\n",
    "    }\n",
    "\n",
    "    coco_licenses = {}\n",
    "    shp_to_coco(outpath/'images', outpath/'vectors', outpath, label_col=target_column, \n",
    "                dataset_name=dataset_name, coco_info=coco_info, coco_categories=coco_cats,\n",
    "                min_bbox_area=min_bbox_area, rotated_bbox=ann_format=='rotated box')\n",
    "    if save_grid: tiler.grid.to_file(outpath/'grid.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f23753-dc3c-48b4-b660-81e6f19b7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@call_parse\n",
    "def create_yolo_dataset(\n",
    "    raster_path:Path, # Path to a raster that is the base for the dataset\n",
    "    polygon_path:Path, # Path to annotated polygons\n",
    "    target_column:str, # Which column contains class information\n",
    "    outpath:Path, # Where to save the resulting files?\n",
    "    dataset_name:str=None, # Optional name of the dataset\n",
    "    gpkg_layer:str=None, # If `polygon_path` is a geopackage, specify the layer used. Ignored otherwise.\n",
    "    min_area_pct:float=0.0, # How small polygons keep after tiling?\n",
    "    save_grid:bool=False, # Should tiling grid be saved?\n",
    "    gridsize_x:int=320, # Size of tiles in x-axis, pixels\n",
    "    gridsize_y:int=320, # Size fo tiles in y-axis, pixels\n",
    "    overlap_x:int=0, # Overlap of tiles in x-axis\n",
    "    overlap_y:int=0, # Overlap of tiles in y-axis\n",
    "    ann_format:str='box', # Annotation format, either box, polygon or rotated box\n",
    "    min_bbox_area:int=0 # Minimum bounding box area in pixels. Smaller objects than this are discarded\n",
    "):\n",
    "    \"Create a YOLO-format dataset from `raster` and `polygon` shapefile\"\n",
    "    tiler = Tiler(outpath, gridsize_x=gridsize_x, gridsize_y=gridsize_y, overlap=(overlap_x, overlap_y))\n",
    "    tiler.tile_raster(raster_path)\n",
    "    tiler.tile_vector(polygon_path)\n",
    "    cats = gpd.read_file(polygon_path)[target_column].unique()\n",
    "    shp_to_yolo(outpath/'images', outpath/'vectors', outpath, label_col=target_column,\n",
    "                names=cats, dataset_name=dataset_name, ann_format=ann_format, min_bbox_area=0)\n",
    "    if save_grid: tiler.grid.to_file(outpath/'grid.geojson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
